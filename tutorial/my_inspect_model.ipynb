{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model_introduction.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                  [-1, 512]         262,656\n",
      "              ReLU-5                  [-1, 512]               0\n",
      "            Linear-6                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 2.55\n",
      "Estimated Total Size (MB): 2.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, ( 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0324, -0.0263,  0.0343,  ...,  0.0243,  0.0218,  0.0338],\n",
      "        [ 0.0351, -0.0176, -0.0068,  ..., -0.0094, -0.0203,  0.0177],\n",
      "        [ 0.0234,  0.0288, -0.0108,  ..., -0.0294, -0.0112,  0.0253],\n",
      "        ...,\n",
      "        [-0.0165,  0.0048, -0.0006,  ...,  0.0285,  0.0147, -0.0183],\n",
      "        [ 0.0032,  0.0218, -0.0188,  ..., -0.0127,  0.0329,  0.0240],\n",
      "        [-0.0260,  0.0208,  0.0315,  ...,  0.0130, -0.0330,  0.0208]],\n",
      "       requires_grad=True)\n",
      "linear_relu_stack.0.bias\n",
      "Parameter containing:\n",
      "tensor([-3.4432e-02, -5.0189e-03, -6.9719e-03,  5.5560e-03,  1.9708e-02,\n",
      "         2.1870e-02, -4.4642e-04, -3.1721e-02, -8.9211e-03,  2.0030e-02,\n",
      "         1.6490e-02, -3.1620e-02, -3.2966e-02,  9.5056e-03,  2.0732e-02,\n",
      "         2.5982e-02,  2.1832e-02, -2.3362e-02,  3.2958e-03,  3.0461e-02,\n",
      "        -1.4453e-03, -3.4082e-02, -7.1843e-04,  2.3915e-02,  2.1642e-02,\n",
      "         1.8923e-02, -2.3175e-02,  4.0660e-02,  1.3049e-02,  4.2878e-02,\n",
      "         2.1402e-02,  2.2724e-02,  2.9015e-02,  2.5201e-02,  2.1127e-02,\n",
      "        -6.4381e-04,  2.6433e-02, -2.2468e-02, -2.3829e-02, -2.7406e-03,\n",
      "         3.0045e-02, -2.8451e-02, -7.5106e-03,  7.9260e-03, -2.0147e-02,\n",
      "         4.4705e-02, -1.1665e-02,  1.4204e-03, -1.1756e-02, -2.5903e-02,\n",
      "        -4.5270e-03,  5.5274e-03, -2.1325e-02,  2.8963e-02, -3.2522e-02,\n",
      "         9.8980e-03,  2.1518e-02, -7.1749e-03,  1.0044e-02,  2.5901e-02,\n",
      "        -7.8845e-03,  3.0900e-02, -2.1483e-02,  1.1674e-02,  1.0955e-02,\n",
      "        -2.5134e-02,  1.6409e-02, -2.1180e-02,  1.7046e-02, -2.6239e-02,\n",
      "         8.0163e-03, -1.8646e-02, -1.3655e-02,  2.6661e-02, -3.0529e-02,\n",
      "        -2.9239e-02, -2.1221e-02, -2.2563e-02, -9.7369e-03, -2.6336e-02,\n",
      "         3.9012e-02, -3.7033e-03,  1.5179e-02,  2.3218e-02,  2.0216e-02,\n",
      "        -2.0549e-02, -5.7695e-03, -2.0550e-02,  7.4355e-03,  3.4183e-02,\n",
      "        -1.2621e-02,  1.6313e-02, -3.0152e-02,  4.0655e-03,  3.3606e-02,\n",
      "        -3.3979e-02, -1.8161e-02,  4.0582e-04, -1.7982e-02, -1.5015e-02,\n",
      "        -5.9412e-03,  2.4858e-02, -4.7795e-03, -1.2118e-02, -4.6944e-03,\n",
      "        -1.4101e-02, -2.7486e-02, -3.0068e-02,  6.0048e-03,  2.2925e-04,\n",
      "        -3.3268e-02,  3.3583e-02,  3.4194e-02,  2.4462e-02, -1.4590e-02,\n",
      "        -3.4271e-02, -2.2447e-02, -3.2528e-02, -1.4933e-03,  2.1208e-03,\n",
      "        -2.3754e-02, -1.7060e-02,  3.1579e-02,  2.9210e-02, -3.0075e-04,\n",
      "        -2.7838e-02,  3.5182e-02, -8.2786e-03,  1.9376e-03,  3.3185e-02,\n",
      "        -2.4496e-02,  4.1662e-02, -6.7709e-03,  1.6678e-02, -1.0549e-02,\n",
      "        -1.1712e-02, -9.2715e-03, -1.8727e-02,  6.9842e-04,  2.6069e-02,\n",
      "         3.4648e-02, -1.6000e-02,  6.4194e-03,  5.6129e-03,  3.4364e-03,\n",
      "        -1.0917e-03,  7.1596e-03,  2.0230e-02, -1.0841e-02, -1.6226e-02,\n",
      "        -2.2356e-02, -1.2072e-02,  1.4588e-03,  3.4586e-02, -3.9913e-03,\n",
      "         1.4134e-02, -6.0771e-03,  2.3787e-02, -6.5099e-03,  1.1415e-02,\n",
      "         2.0707e-02,  2.5637e-02,  1.7472e-02,  3.1433e-02, -2.1045e-02,\n",
      "        -2.1344e-03,  3.0508e-02,  4.3909e-02,  2.9563e-02,  3.6109e-02,\n",
      "         4.6320e-03,  3.3026e-02,  1.5523e-03,  3.5040e-02, -4.6126e-03,\n",
      "        -2.0182e-02, -2.7151e-02, -1.9643e-02, -3.1838e-02,  2.4937e-02,\n",
      "         2.3199e-02,  1.9459e-02, -6.3214e-03,  2.7906e-02, -1.0374e-03,\n",
      "        -1.5521e-02, -1.3721e-02, -4.4216e-04,  1.0847e-02,  2.9802e-02,\n",
      "        -1.8190e-03, -1.3103e-02, -2.4800e-02,  2.1962e-02, -3.0341e-02,\n",
      "         1.9756e-02, -2.0333e-02, -2.2872e-02,  2.5397e-02,  9.4361e-03,\n",
      "        -1.5630e-02,  3.9661e-03, -1.9631e-02, -1.1398e-02,  2.0289e-02,\n",
      "        -1.9785e-02, -2.4633e-02, -2.9173e-02,  2.2062e-02,  3.5133e-02,\n",
      "        -2.7046e-02,  2.7864e-02,  3.1791e-03, -3.5706e-02,  1.2936e-02,\n",
      "         2.5190e-02, -1.4494e-02,  1.7431e-02, -6.0317e-03,  2.6267e-02,\n",
      "         1.1381e-02, -2.2779e-02, -2.7951e-02, -2.2192e-02,  1.9798e-02,\n",
      "         6.9568e-03,  1.8233e-02,  2.1235e-02, -1.7991e-02, -1.6004e-02,\n",
      "         8.7404e-03,  1.0058e-02, -3.2595e-02, -1.4913e-02, -1.9859e-03,\n",
      "         3.3656e-02,  3.2020e-02,  3.0012e-02,  2.3054e-02,  1.4036e-02,\n",
      "        -2.0015e-02,  3.9347e-02, -2.9140e-03, -1.3712e-02, -1.3680e-02,\n",
      "        -2.4052e-02, -2.2078e-02, -7.6389e-03,  3.3486e-03, -8.9052e-03,\n",
      "        -1.0828e-02,  2.8819e-03,  3.4222e-02,  3.5421e-03,  1.6266e-02,\n",
      "         1.9136e-02,  1.7837e-02,  6.6074e-03,  2.1352e-02, -2.3851e-02,\n",
      "        -3.0059e-04, -2.9970e-02, -1.5849e-02,  3.3628e-02, -3.0886e-02,\n",
      "        -1.2366e-04,  3.2398e-02, -2.5863e-02,  5.7820e-03,  8.2529e-03,\n",
      "        -5.3766e-03,  2.3688e-02,  7.0924e-04, -3.2918e-02,  6.3707e-03,\n",
      "         3.1506e-03,  4.9228e-03, -2.9908e-02,  1.7098e-02, -2.7893e-02,\n",
      "        -2.8834e-02, -9.4258e-03, -2.2767e-02, -2.4204e-02, -2.1193e-02,\n",
      "        -2.0421e-02,  1.7818e-02,  4.1580e-02, -6.5446e-03,  4.1981e-02,\n",
      "         3.7617e-02, -2.6317e-03, -2.2231e-03, -5.3935e-03,  2.1204e-02,\n",
      "         2.4677e-02,  3.5995e-02,  3.6437e-03, -9.0864e-03, -1.3360e-02,\n",
      "         4.6965e-02,  5.4781e-03,  2.2435e-02,  3.4266e-02, -1.0713e-02,\n",
      "         1.8258e-02, -7.0701e-03,  2.2849e-02,  1.1694e-02,  2.3132e-02,\n",
      "        -2.8039e-02,  3.4428e-02,  2.2415e-02,  2.4699e-02, -5.4315e-03,\n",
      "        -2.0895e-02, -1.0106e-02, -9.8784e-03, -8.8207e-03,  1.3622e-02,\n",
      "         3.0500e-02,  4.9951e-03,  1.8564e-02, -1.7729e-02, -1.9262e-02,\n",
      "         8.2887e-04,  2.3087e-03,  2.8493e-02,  1.0228e-02, -1.8444e-02,\n",
      "        -2.3579e-02,  3.5377e-03, -1.7480e-02, -1.2220e-02, -1.2070e-02,\n",
      "         8.4924e-03,  8.9186e-03,  9.7156e-03, -2.6891e-03,  1.0191e-03,\n",
      "        -6.3645e-03, -1.8227e-02,  3.0923e-02,  2.5609e-02, -2.4904e-02,\n",
      "         1.7973e-02, -1.7615e-02,  1.8293e-02, -2.4992e-02,  2.4234e-02,\n",
      "         3.3477e-02, -4.9140e-03, -2.1185e-02, -5.3526e-03,  2.2507e-02,\n",
      "        -2.4266e-02, -2.6631e-02, -3.6495e-03,  1.8081e-02, -7.4346e-03,\n",
      "        -1.0229e-02, -2.1681e-02,  3.3234e-03,  1.3643e-02, -2.4465e-02,\n",
      "        -1.0398e-02, -2.5879e-02,  3.4564e-02,  3.3306e-02, -1.2764e-02,\n",
      "        -2.0408e-02,  1.0918e-02, -4.6799e-03,  2.3054e-02,  1.3981e-02,\n",
      "        -1.4012e-02,  3.4197e-02, -3.3542e-02,  4.9971e-03,  3.9103e-04,\n",
      "        -1.5332e-02, -2.7632e-03,  2.9442e-02,  8.7372e-03, -2.7854e-02,\n",
      "         4.1694e-02, -3.3079e-03,  1.3180e-02,  1.7518e-02, -4.5122e-03,\n",
      "        -2.5670e-02,  2.6677e-02,  9.7186e-03, -3.5480e-02,  1.4829e-02,\n",
      "        -5.2965e-03, -3.1386e-02,  6.3789e-03,  1.8975e-02, -3.0218e-02,\n",
      "         7.1021e-03,  2.5948e-02,  1.9091e-05, -2.8411e-02,  2.6697e-02,\n",
      "         2.1919e-02, -2.3164e-02,  4.4337e-02,  2.2198e-02, -2.1829e-02,\n",
      "        -1.2996e-02, -3.3756e-02,  1.0781e-02, -1.5984e-02,  2.2016e-02,\n",
      "         2.0486e-02, -8.2708e-03, -1.5144e-02,  3.2962e-02, -1.6215e-02,\n",
      "        -3.1077e-02,  3.9001e-04,  1.6936e-02, -3.2567e-02,  3.8329e-02,\n",
      "         3.3118e-02, -3.4797e-02,  2.6117e-02,  9.3748e-03, -1.4279e-02,\n",
      "         3.3014e-02, -3.3310e-02, -2.0442e-02, -1.3923e-02,  1.7394e-03,\n",
      "         1.3479e-02,  2.2323e-02, -2.6774e-02, -2.5226e-02, -1.9339e-02,\n",
      "        -4.9939e-03,  1.3536e-02,  2.4293e-02,  7.5434e-03, -7.6435e-03,\n",
      "         2.0736e-02, -2.8108e-02, -2.3390e-02, -5.8925e-03,  2.0261e-02,\n",
      "         4.3574e-02, -2.2663e-02, -1.4630e-02,  3.7544e-02,  1.8000e-02,\n",
      "        -2.5261e-02,  1.1770e-03,  3.5359e-02,  2.4247e-02,  2.5783e-02,\n",
      "        -2.9503e-02,  9.5013e-03, -3.5546e-02, -1.3744e-02, -6.9706e-03,\n",
      "        -2.8591e-02,  3.3014e-02, -1.7787e-03, -1.9677e-02, -2.0839e-02,\n",
      "         3.8602e-03, -1.2408e-03, -2.3558e-02,  2.2437e-02,  1.0450e-02,\n",
      "        -4.9006e-03, -8.1359e-03,  1.5772e-02,  2.1194e-03, -8.7426e-03,\n",
      "        -2.8254e-02, -1.0911e-02, -3.2749e-02, -5.7182e-03, -1.7820e-02,\n",
      "        -1.4259e-02,  1.8144e-02, -2.4854e-02, -1.5847e-02, -8.1335e-03,\n",
      "        -2.7274e-02,  2.5626e-02, -3.1071e-02,  1.3365e-02,  2.9197e-02,\n",
      "        -4.2992e-04,  3.7282e-03,  2.8608e-02, -3.4165e-02,  2.9220e-02,\n",
      "        -3.9677e-03, -3.4485e-02,  2.6270e-02, -5.9241e-04, -2.8519e-03,\n",
      "         1.5246e-02,  2.1135e-02, -2.2545e-02, -1.5421e-02,  3.7748e-03,\n",
      "         1.3891e-02, -9.0283e-03], requires_grad=True)\n",
      "linear_relu_stack.2.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0203, -0.0217,  0.0443,  ..., -0.0434, -0.0166, -0.0416],\n",
      "        [ 0.0196, -0.0337, -0.0270,  ...,  0.0111, -0.0368, -0.0134],\n",
      "        [ 0.0406, -0.0147, -0.0050,  ...,  0.0316, -0.0024, -0.0086],\n",
      "        ...,\n",
      "        [ 0.0379, -0.0109, -0.0137,  ...,  0.0173,  0.0352, -0.0007],\n",
      "        [ 0.0296, -0.0346, -0.0202,  ..., -0.0189,  0.0170, -0.0420],\n",
      "        [ 0.0159,  0.0419, -0.0160,  ..., -0.0092,  0.0049, -0.0049]],\n",
      "       requires_grad=True)\n",
      "linear_relu_stack.2.bias\n",
      "Parameter containing:\n",
      "tensor([ 3.1774e-02,  3.0986e-02,  3.6812e-02, -2.1045e-02,  3.0204e-02,\n",
      "        -1.9263e-02,  1.1762e-02,  2.7183e-02, -7.0392e-03,  1.4398e-02,\n",
      "         7.3268e-03, -2.3947e-02,  4.7451e-02, -2.0470e-02,  3.2938e-02,\n",
      "        -3.8555e-02, -1.3276e-02,  7.8503e-05, -6.3999e-03, -3.4151e-03,\n",
      "        -1.3077e-02,  2.0439e-02,  2.8301e-02,  1.0397e-02,  4.8504e-06,\n",
      "        -3.2500e-02,  4.1812e-02, -2.0044e-02,  2.8871e-02,  5.0312e-03,\n",
      "         1.7297e-02, -2.3833e-02, -2.3512e-02, -3.8616e-02,  2.2789e-02,\n",
      "         2.2896e-02, -2.0481e-02,  4.0469e-02, -2.2893e-02, -4.1214e-03,\n",
      "        -8.5497e-03, -2.9282e-02, -3.8106e-03,  1.2363e-02, -3.5451e-02,\n",
      "         1.8885e-02,  3.4696e-02,  2.2514e-02,  1.4579e-02,  5.0545e-04,\n",
      "        -3.1899e-03,  3.6521e-02, -2.5747e-02,  2.5114e-02, -3.8382e-02,\n",
      "         9.5869e-03,  1.7161e-02,  1.1039e-02,  4.3585e-02, -1.1246e-02,\n",
      "         3.1418e-03,  2.5473e-02, -2.9296e-02,  1.1643e-02,  1.2785e-02,\n",
      "         1.6179e-02,  3.0694e-02, -1.2630e-02,  3.6813e-02,  2.2620e-02,\n",
      "        -8.0909e-03,  3.1557e-02,  3.2647e-02,  2.8026e-02,  4.3180e-02,\n",
      "         1.0886e-02, -8.9726e-03,  4.3620e-03,  1.1741e-02,  2.4140e-02,\n",
      "        -2.9893e-02, -5.3136e-03, -3.3143e-02,  1.1010e-02, -4.3236e-02,\n",
      "        -1.4187e-02, -1.1358e-02, -3.3856e-02, -3.0687e-02,  3.0309e-02,\n",
      "        -1.9505e-03, -5.1464e-03,  2.2395e-02, -6.6059e-04, -1.0203e-02,\n",
      "        -3.8268e-02,  1.1457e-02, -3.5463e-02,  4.3760e-02, -1.3300e-02,\n",
      "        -1.9256e-02, -1.9296e-02,  3.2136e-02,  4.8516e-02, -2.9829e-02,\n",
      "        -2.4980e-02, -1.4665e-02,  3.3527e-02,  1.2504e-03, -4.3345e-03,\n",
      "        -3.2929e-02, -1.2471e-02, -2.1230e-03,  3.0692e-02, -1.5070e-02,\n",
      "         4.2143e-02, -3.5082e-02,  1.2458e-02,  4.0770e-02, -4.1880e-02,\n",
      "         1.8619e-02,  4.2470e-02, -3.2183e-02,  1.0172e-02, -2.4102e-02,\n",
      "         3.4147e-02, -3.5120e-02, -3.3531e-02,  2.4449e-02,  3.9992e-02,\n",
      "        -3.2053e-02,  3.0129e-02, -2.3250e-02,  3.9030e-02,  2.2301e-02,\n",
      "         2.8439e-02, -2.8788e-02, -3.8086e-02,  5.6977e-04,  3.5083e-02,\n",
      "        -4.6111e-04, -2.6607e-02,  8.2426e-03, -3.8452e-03, -3.9773e-02,\n",
      "         2.3109e-02, -2.7832e-02,  4.6801e-02,  2.0749e-02, -3.9622e-02,\n",
      "        -2.5710e-02,  3.7852e-02, -3.3162e-03,  4.2625e-02, -4.5381e-03,\n",
      "        -2.6433e-02, -2.5803e-02,  3.7270e-02, -1.4202e-02,  2.5621e-02,\n",
      "         4.2512e-02, -2.3906e-02,  1.8026e-02,  2.8384e-02,  4.7761e-04,\n",
      "         2.7453e-02,  5.5525e-02, -2.3531e-03,  2.7994e-02, -3.0839e-02,\n",
      "         2.7756e-02, -2.7400e-02, -6.9585e-03, -3.2254e-02,  1.3530e-02,\n",
      "         3.7893e-02, -1.8357e-02,  1.4225e-02,  2.0202e-02, -4.1824e-02,\n",
      "         3.4956e-03,  4.1588e-02,  4.2034e-02,  4.1695e-03,  3.5548e-02,\n",
      "         1.2342e-02, -2.1938e-02, -2.6806e-02,  4.0043e-02,  1.5589e-02,\n",
      "         4.6388e-02, -3.5013e-02, -8.0254e-03, -2.0594e-02,  1.2575e-02,\n",
      "         1.6544e-02,  1.4565e-02,  3.7695e-02, -1.9509e-02,  7.7326e-03,\n",
      "        -3.4487e-02,  1.1370e-02,  2.1626e-02,  4.3814e-03, -2.2906e-02,\n",
      "         3.9283e-04,  3.0212e-02,  4.0659e-02,  2.6768e-02, -1.7528e-02,\n",
      "        -3.6744e-02, -1.7485e-02,  3.4067e-02,  3.5696e-02, -3.1873e-02,\n",
      "        -4.9980e-04, -2.5952e-02, -1.1512e-02, -2.5530e-02,  3.0936e-02,\n",
      "         9.8568e-03,  2.8208e-02,  2.2746e-02,  1.7622e-02, -3.2475e-02,\n",
      "         3.0237e-02,  3.9016e-02, -1.0497e-02, -6.2886e-03, -6.4635e-03,\n",
      "        -3.6709e-02,  3.3498e-02, -5.5757e-03, -1.5479e-02,  2.1504e-02,\n",
      "         1.1223e-02,  1.1571e-02, -5.6238e-04,  2.6696e-02,  3.2508e-03,\n",
      "         1.2344e-02, -2.9544e-02,  2.0390e-02,  1.8324e-03, -1.1721e-02,\n",
      "         3.6947e-02,  6.4460e-03,  2.3693e-02, -2.5048e-02,  5.5165e-04,\n",
      "        -6.0496e-03,  4.8535e-02, -1.3478e-02, -2.4502e-03,  4.1598e-02,\n",
      "        -1.4413e-02,  4.2430e-02, -2.8068e-02, -3.1387e-02,  4.2307e-02,\n",
      "         1.3411e-02, -3.7724e-02,  2.1638e-02,  4.8165e-02, -3.0364e-02,\n",
      "        -2.4266e-02,  1.9298e-02, -1.1249e-02, -2.0658e-02,  1.4065e-02,\n",
      "        -2.5154e-02,  2.0234e-02, -2.8474e-02, -4.0951e-03,  3.6569e-02,\n",
      "         3.2081e-02,  2.5945e-02,  4.2858e-03,  4.2469e-02, -7.6086e-03,\n",
      "         7.9833e-03,  1.4897e-02,  2.8216e-02,  7.8969e-03, -5.6878e-03,\n",
      "         1.5106e-02,  3.3822e-02,  8.7475e-03,  5.1392e-02,  3.6698e-04,\n",
      "         3.5243e-03,  5.6038e-03, -3.6283e-02, -1.8251e-02, -2.4358e-02,\n",
      "        -2.4263e-02,  2.8573e-02, -4.1094e-02, -1.7110e-02,  1.0986e-02,\n",
      "        -2.1752e-02, -4.3321e-02, -1.8160e-02, -2.4648e-02,  2.5935e-02,\n",
      "         5.2898e-02, -7.4037e-03,  3.6660e-02, -2.4878e-02,  1.7482e-02,\n",
      "         4.8237e-03,  4.1712e-02, -4.0919e-02,  7.9503e-03,  1.6274e-02,\n",
      "        -2.1829e-02, -4.2462e-02,  4.1953e-02, -1.7097e-02,  3.9077e-02,\n",
      "         4.9947e-03, -3.1298e-02,  2.0563e-02,  3.3415e-02, -1.5300e-02,\n",
      "        -2.1240e-02, -6.5192e-03,  2.4203e-02, -2.0928e-03, -1.8626e-02,\n",
      "         1.1920e-02,  2.0644e-02, -3.2432e-02, -9.5818e-03,  3.4419e-02,\n",
      "         1.4864e-02,  2.6388e-02,  3.8761e-02, -3.0006e-02, -3.4028e-02,\n",
      "        -2.8144e-02,  2.2713e-02,  1.0564e-02,  2.9385e-02,  1.3639e-02,\n",
      "        -3.1742e-02, -3.9126e-02,  1.0558e-02,  9.7437e-04, -3.4695e-02,\n",
      "        -1.0200e-02, -1.6593e-02, -1.3389e-02,  7.9801e-03,  4.2690e-02,\n",
      "         6.7212e-03, -1.6817e-02,  6.9878e-03,  4.4647e-02, -1.5449e-02,\n",
      "         1.2992e-02, -3.7463e-02, -2.8341e-02, -2.4270e-02,  2.7648e-02,\n",
      "        -1.7371e-02,  3.3481e-02,  2.8309e-02,  3.5119e-02, -2.7513e-02,\n",
      "         3.7912e-02,  4.3527e-02, -3.5601e-02,  1.9692e-02,  1.4798e-02,\n",
      "         3.3411e-02, -3.9750e-03,  1.1427e-02, -1.5859e-02,  2.9547e-02,\n",
      "        -2.5802e-02, -2.2642e-02,  3.5625e-02, -3.1490e-02, -3.3857e-02,\n",
      "        -2.0084e-02, -2.1010e-02,  1.8492e-02,  4.4951e-02, -7.4429e-03,\n",
      "         2.7988e-02, -5.9573e-04,  7.4064e-04,  4.2609e-02,  3.1506e-02,\n",
      "        -5.2364e-03, -3.8993e-02,  3.4437e-02, -1.7723e-02,  3.8445e-02,\n",
      "        -2.8533e-02, -1.2707e-02, -5.6150e-03, -1.9776e-02, -4.2147e-02,\n",
      "        -1.5788e-02, -1.2084e-02,  3.0171e-02,  1.7566e-02,  1.2158e-02,\n",
      "         3.9016e-02,  5.7485e-02,  4.1991e-02,  2.4786e-02, -1.0190e-02,\n",
      "        -1.2665e-02, -3.9063e-02,  3.0424e-02, -2.3896e-02, -1.8184e-02,\n",
      "         4.1901e-02,  1.7418e-04, -3.4782e-02,  3.6077e-02, -4.9276e-03,\n",
      "        -3.0911e-02, -1.9742e-02,  4.1598e-02,  6.4073e-03, -3.6668e-04,\n",
      "         1.5546e-03,  2.1664e-02,  1.6222e-02,  1.2304e-02,  3.1627e-02,\n",
      "        -3.7180e-02, -3.2016e-02,  3.6025e-02, -4.0443e-02, -2.1389e-02,\n",
      "         4.5054e-02, -1.6866e-02,  2.1861e-02,  2.6415e-02,  2.2839e-02,\n",
      "         2.4410e-02,  4.3991e-02, -4.3291e-02,  4.3580e-02,  3.8896e-02,\n",
      "        -1.8429e-02,  2.8395e-02, -1.2451e-02, -1.0522e-02,  1.9766e-02,\n",
      "         2.6210e-03,  6.1115e-02,  3.0314e-02,  1.5806e-02, -3.7442e-02,\n",
      "        -3.6982e-03,  3.1022e-02, -1.4707e-03,  1.1210e-02, -2.1125e-02,\n",
      "         3.2802e-02,  8.2155e-03, -1.5987e-02, -2.2399e-02, -3.0655e-02,\n",
      "        -2.7309e-02, -3.9831e-03,  3.8610e-02, -4.2527e-02,  7.6752e-03,\n",
      "        -1.2451e-02, -3.1669e-02,  1.4440e-02,  1.9435e-02, -1.1698e-02,\n",
      "         2.0675e-02,  3.0418e-02,  4.4663e-02,  1.3501e-02,  6.0969e-03,\n",
      "        -3.1696e-02, -1.6212e-02,  3.0613e-03, -1.0831e-03, -3.7014e-02,\n",
      "        -2.1290e-02, -4.1755e-02,  9.9409e-03,  3.4678e-02,  2.2619e-02,\n",
      "        -2.4149e-02, -7.0856e-03, -3.9413e-02,  2.8813e-02, -2.5207e-02,\n",
      "         1.3182e-02,  2.0758e-02,  4.5469e-02,  2.2105e-02, -1.4494e-02,\n",
      "         4.3581e-03, -8.4965e-03, -2.6761e-02,  2.9678e-02,  3.4865e-02,\n",
      "         4.6279e-03,  3.3117e-02], requires_grad=True)\n",
      "linear_relu_stack.4.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0126,  0.0160,  0.0405,  ..., -0.0148, -0.0479, -0.0458],\n",
      "        [ 0.0016, -0.0096,  0.0101,  ..., -0.0419,  0.0545,  0.0522],\n",
      "        [-0.0347, -0.0184,  0.0348,  ...,  0.0078, -0.0222, -0.0786],\n",
      "        ...,\n",
      "        [-0.0646,  0.0276,  0.0066,  ..., -0.0307,  0.0047, -0.0174],\n",
      "        [-0.0215, -0.0205,  0.0099,  ..., -0.0475,  0.0415, -0.0554],\n",
      "        [-0.0192, -0.0149, -0.0106,  ..., -0.0446, -0.0166, -0.0062]],\n",
      "       requires_grad=True)\n",
      "linear_relu_stack.4.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0222, -0.0237, -0.0202,  0.0384, -0.1083,  0.1479, -0.0358,  0.0630,\n",
      "        -0.0490,  0.0117], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    #print(param)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48d70102b39d95aead4b26bba9bbe9be19e9a8a8ccc40763b3f585c0ed78ce8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
